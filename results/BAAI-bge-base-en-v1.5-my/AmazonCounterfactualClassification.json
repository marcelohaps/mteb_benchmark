{
  "dataset_revision": "589b8cdf671a2e80745f3443de8e52f70d8c296f",
  "mteb_dataset_name": "AmazonCounterfactualClassification",
  "mteb_version": "1.2.1.dev0",
  "test": {
    "EN": {
      "accuracy": 0.7222388059701492,
      "accuracy_stderr": 0.03451893885499322,
      "ap": 0.3312294424040213,
      "ap_stderr": 0.020364952363597047,
      "f1": 0.653135350256316,
      "f1_stderr": 0.025491431984497027,
      "main_score": 0.7222388059701492
    },
    "EN-ext": {
      "accuracy": 0.7110944527736132,
      "accuracy_stderr": 0.048774280874171676,
      "ap": 0.17645654453077736,
      "ap_stderr": 0.020229392165988604,
      "f1": 0.5685327526955462,
      "f1_stderr": 0.03346309222719949,
      "main_score": 0.7110944527736132
    },
    "evaluation_time": 43.94
  },
  "validation": {
    "EN": {
      "accuracy": 0.7077611940298507,
      "accuracy_stderr": 0.04285323895701122,
      "ap": 0.2724799313508395,
      "ap_stderr": 0.022725899856750588,
      "f1": 0.6172938949222259,
      "f1_stderr": 0.03133966798198467,
      "main_score": 0.7077611940298507
    },
    "EN-ext": {
      "accuracy": 0.6936936936936937,
      "accuracy_stderr": 0.04969039949999533,
      "ap": 0.15889548253237448,
      "ap_stderr": 0.014166111851902264,
      "f1": 0.5487844793530509,
      "f1_stderr": 0.02984856111466064,
      "main_score": 0.6936936936936937
    },
    "evaluation_time": 39.44
  }
}