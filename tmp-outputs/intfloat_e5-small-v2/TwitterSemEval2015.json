{
  "dataset_revision": "96a34e0f57b76f0a8a5ad54239329f3602f49edc",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.1.dev0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8052046969216122,
      "accuracy_threshold": 0.9392225742340088,
      "ap": 0.5162941135996447,
      "f1": 0.5043616177636796,
      "f1_threshold": 0.9090762138366699,
      "precision": 0.4702982499383781,
      "recall": 0.5437446565973212
    },
    "dot": {
      "accuracy": 0.8052046969216122,
      "accuracy_threshold": 0.9392226338386536,
      "ap": 0.5162944238544477,
      "f1": 0.5043616177636796,
      "f1_threshold": 0.9090762138366699,
      "precision": 0.4702982499383781,
      "recall": 0.5437446565973212
    },
    "euclidean": {
      "accuracy": 0.8052046969216122,
      "accuracy_threshold": 0.3486471176147461,
      "ap": 0.5162943539173308,
      "f1": 0.5043616177636796,
      "f1_threshold": 0.42643582820892334,
      "precision": 0.4702982499383781,
      "recall": 0.5437446565973212
    },
    "evaluation_time": 97.86,
    "manhattan": {
      "accuracy": 0.8047603935258648,
      "accuracy_threshold": 5.659045219421387,
      "ap": 0.5156792564054554,
      "f1": 0.5056393359523508,
      "f1_threshold": 6.732182502746582,
      "precision": 0.45527156549520764,
      "recall": 0.5685380450270733
    },
    "max": {
      "accuracy": 0.8052046969216122,
      "ap": 0.5162944238544477,
      "f1": 0.5056393359523508
    }
  }
}