{
  "dataset_revision": "96a34e0f57b76f0a8a5ad54239329f3602f49edc",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.1.dev0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8180260234846081,
      "accuracy_threshold": 0.9112570881843567,
      "ap": 0.5710635347581392,
      "f1": 0.5539869281045752,
      "f1_threshold": 0.8873615264892578,
      "precision": 0.5117121468244386,
      "recall": 0.603875748076375
    },
    "dot": {
      "accuracy": 0.8180260234846081,
      "accuracy_threshold": 0.9112570285797119,
      "ap": 0.5710623497012021,
      "f1": 0.5539869281045752,
      "f1_threshold": 0.8873615264892578,
      "precision": 0.5117121468244386,
      "recall": 0.603875748076375
    },
    "euclidean": {
      "accuracy": 0.8180260234846081,
      "accuracy_threshold": 0.42129066586494446,
      "ap": 0.5710633617704175,
      "f1": 0.5539869281045752,
      "f1_threshold": 0.47463342547416687,
      "precision": 0.5117121468244386,
      "recall": 0.603875748076375
    },
    "evaluation_time": 99.75,
    "manhattan": {
      "accuracy": 0.8178356077435734,
      "accuracy_threshold": 6.509042739868164,
      "ap": 0.5704935489069065,
      "f1": 0.5519978830378407,
      "f1_threshold": 7.365795612335205,
      "precision": 0.5151889355396394,
      "recall": 0.5944713593616415
    },
    "max": {
      "accuracy": 0.8180260234846081,
      "ap": 0.5710635347581392,
      "f1": 0.5539869281045752
    }
  }
}